(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{571:function(t,s,a){"use strict";a.r(s);var e=a(40),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"examples"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#examples"}},[t._v("#")]),t._v(" Examples")]),t._v(" "),a("p",[t._v("This doc will show you the basics of how to send and receive data and give you an overview of the functionality with in SpecklePy. However, it is not comprehensive. Feel free to explore the repo's "),a("a",{attrs:{href:"https://github.com/specklesystems/speckle-py/tree/main/tests",target:"_blank",rel:"noopener noreferrer"}},[t._v("tests"),a("OutboundLink")],1),t._v(" for even more examples.")]),t._v(" "),a("h2",{attrs:{id:"sending-receiving"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sending-receiving"}},[t._v("#")]),t._v(" Sending & Receiving")]),t._v(" "),a("p",[t._v("Let's look at how to send an object to a stream on your server, then receive that object back.")]),t._v(" "),a("p",[t._v("First, you'll need to create and authenticate a client. To use the client, you'll need access to a Speckle server. To authenticate the client, you'll either need local accounts (added using "),a("a",{attrs:{href:"/user/manager"}},[t._v("Manager")]),t._v(") or you can go to "),a("code",[t._v("your-server.com/profile")]),t._v(" and create a Personal Access Token.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SpeckleClient\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("credentials "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" get_default_account\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# initialise the client")]),t._v("\nclient "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SpeckleClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your-server.com"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or whatever your host is")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# client = SpeckleClient(host="localhost:3000", use_ssl=False) or use local server')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# authenticate the client with a token")]),t._v("\naccount "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_default_account"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nclient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("authenticate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("account"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("token"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Now that you have an authenticated client, you can start interacting with the API. Let's create a new stream and get that stream back.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a new stream. this returns the stream id")]),t._v("\nnew_stream_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a shiny new stream"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use that stream id to get the stream from the server")]),t._v("\nnew_stream "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("new_stream_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Next, we'll need some data to send. To make it more interesting, let's extend "),a("code",[t._v("Base")]),t._v(" to create a simple block. All your custom objects should inherit from "),a("code",[t._v("Base")]),t._v(" to ensure serialisation will work as expected.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("point "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Point\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Block")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v("\n    width"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v("\n    height"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v("\n    origin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mark the origin as a detachable attribute")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_detachable_attrs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"origin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Now let's send a block to the server! To do this, you'll first need to send the object to the stream and get back the object id or hash. You can then use this to create a commit on the stream that references this object.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# here's the data you want to send")]),t._v("\nblock "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Block"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" height"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# next create a server transport - this is the vehicle through which you will send and receive")]),t._v("\ntransport "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ServerTransport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("client"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stream_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("new_stream_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this serialises the block and sends it to the transport")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" operations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("send"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("block"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transports"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("transport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# you can now create a commit on your stream with this object")]),t._v("\ncommid_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    stream_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("new_stream_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    obj_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    message"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"this is a block I made in speckle-py"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Tada! You should now have a commit on your stream containing your block. You'll be able to see the commit on the stream page on the web. Receiving an object back is pretty similar to receiving it. You'll generally be using the client to get a commit, then getting the hash to receive from the "),a("code",[t._v("referencedObject")]),t._v(" attribute on that commit.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this receives the object back from the transport.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the received data will be deserialised back into a `Block` ")]),t._v("\nreceived_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" operations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("receive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" remote_transport"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("transport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"overview-of-functionality"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#overview-of-functionality"}},[t._v("#")]),t._v(" Overview of Functionality")]),t._v(" "),a("h3",{attrs:{id:"graphql-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#graphql-client"}},[t._v("#")]),t._v(" GraphQL Client")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("SpeckleClient")]),t._v(" is the entry point for interacting with the GraphQL API. You'll need to have access to a speckle server to use this. To authenticate, you'll need a token. You can either get one from an account you've already added to your computer using the "),a("a",{attrs:{href:"/user/manager"}},[t._v("Manager")]),t._v(" or you can head to "),a("code",[t._v("your-server.com/profile")]),t._v(" and create a Personal Access Token.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SpeckleClient\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("credentials "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" get_default_account"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" get_local_accounts\n\nall_accounts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_local_accounts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get back a list")]),t._v("\naccount "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_default_account"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nclient "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SpeckleClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your-server.com"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or whatever your host is")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# client = SpeckleClient(host="localhost:3000", use_ssl=False) or use local server')]),t._v("\n\nclient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("authenticate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("account"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("token"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Interacting with streams is designed to be intuitive and evocative of SpecklePy 1.0")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get a list of your most recent streams")]),t._v("\nstream_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# search your streams")]),t._v("\nresults "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("search"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mech"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a stream")]),t._v("\nnew_stream_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a shiny new stream"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get a stream")]),t._v("\nnew_stream "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("new_stream_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("New in 2.0: branches and commits! Here are some basic interactions.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get list of commits")]),t._v("\ncommits "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get a specific commit")]),t._v("\ncommit "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"commit_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a commit")]),t._v("\ncommit_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    stream_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" obj_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"object_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" message"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"this is a commit message to describe the commit"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# delete a commit")]),t._v("\ndeleted "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"commit_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get a list of branches")]),t._v("\nbranches "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("branch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a branch")]),t._v("\nbranch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("branch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"branch name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a description of the branch"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get a specific branch")]),t._v("\nbranch "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("branch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"branch name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h3",{attrs:{id:"operations-and-transports"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#operations-and-transports"}},[t._v("#")]),t._v(" Operations and Transports")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("operations")]),t._v(" includes four main methods:")]),t._v(" "),a("ol",[a("li",[a("code",[t._v("send")]),t._v(": send an object to a stream")]),t._v(" "),a("li",[a("code",[t._v("receive")]),t._v(": receive an object from a stream")]),t._v(" "),a("li",[a("code",[t._v("serialize")]),t._v(": serialise a given "),a("code",[t._v("Base")]),t._v(" object")]),t._v(" "),a("li",[a("code",[t._v("deserialize")]),t._v(": deserializes json into an object into the type specified in "),a("code",[t._v("speckle_type")]),t._v(" (defaults to a vanilla "),a("code",[t._v("Base")]),t._v(" if the type can't be found)")])]),t._v(" "),a("p",[t._v("Let's look at sending and receiving. You will need to provide a transport to indicate where the objects should be sent / received from. When sending, you can provide multiple transports to send the same object to multiple places simultaneously. At the moment, we have three transports: "),a("code",[t._v("SQLiteTransport")]),t._v(", "),a("code",[t._v("MemoryTransport")]),t._v(", and "),a("code",[t._v("ServerTransport")]),t._v(". If you'd like to learn more about Transports in Speckle 2.0, have a look "),a("a",{attrs:{href:"/dev/transports"}},[t._v("here")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transports"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("memory "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MemoryTransport\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" operations\n\ntransport "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MemoryTransport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this serialises the object and sends it to the transport")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" operations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("send"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transports"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("transport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if the object had detached objects, you can see these as well")]),t._v("\nsaved_objects "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# a dict with the obj hash as the key")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this receives and object from the given transport, deserialises it,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# and recomposes it into a base object.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# you can optionally provide a local_transport which will default to")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the `SQLiteTransport` pointing at your local cache")]),t._v("\nreceived_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" operations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("receive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" remote_transport"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("transport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("You can also use the GraphQL API to send and receive objects. However, note that this method will not recompose a base and will only get the object you explicitly ask for using by its id.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a test base object")]),t._v("\ntest_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("testing "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a test base obj"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# run it through the serialiser")]),t._v("\ns "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BaseObjectSerializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" obj "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("traverse_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send it to the server")]),t._v("\nobjCreate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stream_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" objects"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nreceived_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stream id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"base-object-serialization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#base-object-serialization"}},[t._v("#")]),t._v(" Base Object & Serialization")]),t._v(" "),a("h4",{attrs:{id:"the-base-object"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-base-object"}},[t._v("#")]),t._v(" The Base Object")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("Base")]),t._v(" class is the one you're familiar with from the rest of the Speckle universe. It generally behaves the same way as it does in the other SDKs. For more info about the "),a("code",[t._v("Base")]),t._v(" object, have a look "),a("a",{attrs:{href:"/dev/base"}},[t._v("here")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# creating a base we will nest within a parent base")]),t._v("\ndetached_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndetached_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a detached base"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# creating our parent base object")]),t._v("\nbase_obj "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# attributes can be added using dot or dict notation")]),t._v("\nbase_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my base"')]),t._v("\nbase_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"colour"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lilac"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# other base objects can be nested within.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prepending the attribute name with `@` will detach the nested base when sending")]),t._v("\nbase_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@nested"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" detached_base\n")])])]),a("p",[t._v("The "),a("code",[t._v("Base")]),t._v(" class has a few handy instance methods for identifying your object's typed and dynamic attributes:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("get_typed_member_names()")]),t._v(" gets all of the names of the defined (typed) attributes of the object")]),t._v(" "),a("li",[a("code",[t._v("get_dynamic_member_names()")]),t._v(" gets all of the names of the dynamic attributes of the object")]),t._v(" "),a("li",[a("code",[t._v("get_member_names()")]),t._v(" gets a list of all the attributes on the object, dynamic or not")])]),t._v(" "),a("p",[t._v("Each "),a("code",[t._v("Base")]),t._v(" object has an "),a("code",[t._v("id")]),t._v(" (a unique hash) as it does in the other SDKs. This field is only populated if the "),a("code",[t._v("Base")]),t._v(" has been previously serialised. If you really need the hash, you can get it using the "),a("code",[t._v("get_id()")]),t._v(" method. Be aware that if the "),a("code",[t._v("id")]),t._v(" is not populated, this call will fully serialise the object to create the "),a("code",[t._v("id")]),t._v("! By default, the hash will be generated without decomposing the object. However, you can pass "),a("code",[t._v("decompose=True")]),t._v(" as an argument if you want the decomposed "),a("code",[t._v("id")]),t._v(".")]),t._v(" "),a("h4",{attrs:{id:"subclassing-base"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#subclassing-base"}},[t._v("#")]),t._v(" Subclassing Base")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("Base")]),t._v(" class can be subclassed to create your own custom objects. These are automatically added to a a class level registry which is simply a dictionary with the type name as the key. The type is automatically populated by the "),a("code",[t._v("speckle_type")]),t._v(" attribute, but can be overwritten when writing your class.")]),t._v(" "),a("p",[t._v("Note that all typed attributes of a class must be initialised with a default value for serialisation purposes.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("point "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Point\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Line")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AlternativeLine")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" speckle_type"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Line_Two"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    The `speckle_type` is automatically populated by the class name.\n    You can override this behaviour as demonstrated here.\n    """')]),t._v("\n    a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# look, a new custom line!")]),t._v("\nline "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# adding dynamic attributes as normal")]),t._v("\nline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blah "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blah"')]),t._v("\nline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"colour"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),t._v("\n")])])]),a("p",[t._v("You can also mark typed attributes as detachable or chunkable by updating the internal "),a("code",[t._v("_detachable")]),t._v(" set or "),a("code",[t._v("_chunkable")]),t._v(" dict with the provided helper methods.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# members that are chunked upon sending are stored in a dictionary")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# with the name as the key and the maximum chunk size as the value")]),t._v("\nCHUNKABLE_PROPS "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"vertices"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"faces"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"colors"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"textureCoordinates"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test_bases"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# detachable members are just added to an internal set by name")]),t._v("\nDETACHABLE "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"detach_this"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"origin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FakeMesh")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    faces"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    colors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    textureCoordinates"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    test_bases"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    detach_this"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    _origin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You\'ll need an init method to add your chunkable and detachable members"""')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_chunkable_attrs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("CHUNKABLE_PROPS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# add the chunkables")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_detachable_attrs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("DETACHABLE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# add the detachables")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# properties are also picked up and serialised as you'd expect")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@property")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("origin")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_origin\n\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@origin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setter")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("origin")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_origin "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" value\n\n")])])]),a("h4",{attrs:{id:"serialization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#serialization"}},[t._v("#")]),t._v(" Serialization")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("BaseObjectSerializer")]),t._v(" is what's used behind the scenes in the "),a("code",[t._v("operations")]),t._v(" for decomposing and serializing "),a("code",[t._v("Base")]),t._v(" objects so they can be sent / received to the server. You probably won't ever need to use it directly. However, if you want you can use it to get the id (hash) and a serializable object representation of the decomposed "),a("code",[t._v("Base")]),t._v(". You can learn more about the Speckle "),a("code",[t._v("Base")]),t._v(" object "),a("a",{attrs:{href:"/dev/base"}},[t._v("here")]),t._v(" and the decomposition API "),a("a",{attrs:{href:"/dev/decomposition"}},[t._v("here")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("objects "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Base\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" specklepy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serialization"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("base_object_serializer "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BaseObjectSerializer\n\ndetached_base "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndetached_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a detached base"')]),t._v("\n\nbase_obj "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbase_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my base"')]),t._v("\nbase_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@nested"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" detached_base\n\nserializer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BaseObjectSerializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" obj_dict "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" serializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("traverse_base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" serialized "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" serializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write_json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndeserialized "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" serializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("serialized"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);